{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCDHAS Pipeline Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through how to run Karl Misselt's NCDHAS pipeline and reduce CV3 data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NCDHAS ramps-to-slopes pipeline is installed on the JWST witserv, so you must remotely login to the server via SSH to access the pipeline. We currently have version 107. Karl said he has a version 108 for OTIS testing, but this version was not given to us. To install the newer version onto witserv, we have to submit a ticket through ITSD after Karl sends us his new version.\n",
    "\n",
    "First, log in to witserv:\n",
    "    \n",
    "        % ssh -XY username@witserv<#>.stsci.edu\n",
    "    \n",
    "        Where <#> is 1, 2, or 3 and username is your AD username.\n",
    "    \n",
    "From witserv, you can set the environment variables to access NCDHAS. However, I prefer to run it from within my JWST pipeline environment so I can compare the results. Once you are in your preferred server environment, set the environment variables:\n",
    "\n",
    "        Under csh, tcsh:\n",
    "        % setenv NCDHAS_PATH /grp/software/Linux/RH6/x86_64/ncdhas\n",
    "        % setenv PATH ${NCDHAS_PATH}:${PATH}\n",
    " \n",
    "        Under bash:\n",
    "        % export NCDHAS_PATH=/grp/software/Linux/RH6/x86_64/ncdhas\n",
    "        % export PATH=$PATH:$NCDHAS_PATH\n",
    "    \n",
    "** To run the pipeline in this notebook, you must open the notebook from within your NCDHAS pipeline environment! \"shift+enter\" is the hot key to run a cell of the notebook. **   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Plotting and Analysis Modules\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# define some functions for easier plotting and analysis\n",
    "\n",
    "# display image\n",
    "\n",
    "def display_img(image, vmin, vmax):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.ylabel('y pixels',fontsize=22)\n",
    "    plt.xlabel('x pixels',fontsize=22)\n",
    "    plt.imshow(image, vmin = vmin, vmax=vmax, cmap=plt.cm.gray, origin='lower')\n",
    "    plt.colorbar(orientation='horizontal',pad=0.05) \n",
    "    return plt\n",
    "\n",
    "\n",
    "# define function for easier plotting of pixels\n",
    "\n",
    "def plot_pixel(image, xpix, ypix, label, ax, color, ymin, ymax, xmin, xmax,mode):\n",
    "    nframe = readpatts[mode.lower()]['nframe']\n",
    "    nskip = readpatts[mode.lower()]['nskip']\n",
    "    ngroup = readpatts[mode.lower()]['ngroup']\n",
    "    tgroup = readpatts[mode.lower()]['tgroup']\n",
    "    dataloc = (nframe+nskip)/2\n",
    "    ax.plot(np.arange(dataloc,len(image)*(nframe+nskip)+dataloc,(nframe+nskip))*10.73676, image[:,ypix,xpix], label=label, marker='d',markersize=10, color=color)\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlim(xmin-tgroup,xmax*tgroup+tgroup)\n",
    "    ax.legend(loc='best')\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "# find saturated pixel by looking for pixel w/ signal level higher than some threshold (DN)\n",
    "# e.g. jj,ii = find_sat_pix(image,60000)\n",
    "\n",
    "def find_sat_pix(data,threshold):\n",
    "    saturated = np.where(data > threshold)\n",
    "    ii = saturated[2][0]\n",
    "    jj = saturated[1][0]\n",
    "    return jj, ii\n",
    "\n",
    "\n",
    "# find cosmic rays by looking for pixels w/ signal differences higher given threshold (integer)\n",
    "# e.g. nn,mm = find_cr_pix(image,5)\n",
    "\n",
    "def find_cr_pix(data,threshold):\n",
    "    coords = []\n",
    "    readnoise = 16\n",
    "    #loop over pixel coordinate combinations \n",
    "    # full array would be (0,2048)\n",
    "    for i,j in itertools.product(np.arange(300,800), np.arange(300,800)):\n",
    "        y = data[:,j,i]\n",
    "        # this method is a simplified version of what the pipeline does\n",
    "        ydiff = np.abs(np.diff(y))\n",
    "        poisson_noise = np.sqrt(np.abs(ydiff))\n",
    "        yerr_exp = np.sqrt(poisson_noise*poisson_noise + readnoise*readnoise)\n",
    "        ratio = ydiff/yerr_exp\n",
    "        candidate = ratio.argmax()\n",
    "        if ratio[candidate] > threshold:\n",
    "            coords.append([j,i])\n",
    "        sample = random.sample(coords, 1)\n",
    "    return sample[0][1],sample[0][0]\n",
    "\n",
    "\n",
    "# find bad pixels by loading the appropriate bad pixel mask and choosing a pixel flagged as \"bad\"\n",
    "# e.g. kk,ll = find_bad_pix(\"NRCA1_17004_BPM_ISIMCV3_2016-01-21_ssbspmask_DMSorient.fits\")\n",
    "\n",
    "def find_bad_pix(bpm):\n",
    "    # bpm is the bad pixel mask that will be used for calibration of the file\n",
    "    badpix = np.where(bpm == 5)\n",
    "    mm = badpix[1][0]\n",
    "    nn = badpix[0][1]\n",
    "    return nn,mm\n",
    "\n",
    "\n",
    "# NIRCam readmode dictionary for ramp values\n",
    "\n",
    "deep8 = {}\n",
    "deep8['tgroup'] = 212.\n",
    "deep8['ngroup'] = 20.\n",
    "deep8['nframe'] = 8\n",
    "deep8['nskip'] = 12\n",
    "\n",
    "deep2 = {}\n",
    "deep2['tgroup'] = 212.\n",
    "deep2['ngroup'] = 20.\n",
    "deep2['nframe'] = 2\n",
    "deep2['nskip'] = 18\n",
    "\n",
    "medium8 = {}\n",
    "medium8['tgroup'] = 106.\n",
    "medium8['ngroup'] = 10.\n",
    "medium8['nframe'] = 8\n",
    "medium8['nskip'] = 2\n",
    "\n",
    "medium2 = {}\n",
    "medium2['tgroup'] = 106.\n",
    "medium2['ngroup'] = 10.\n",
    "medium2['nframe'] = 2\n",
    "medium2['nskip'] = 8\n",
    "\n",
    "shallow4 = {}\n",
    "shallow4['tgroup'] = 53.\n",
    "shallow4['ngroup'] = 10.\n",
    "shallow4['nframe'] = 4\n",
    "shallow4['nskip'] = 1\n",
    "\n",
    "shallow2 = {}\n",
    "shallow2['tgroup'] = 53.\n",
    "shallow2['ngroup'] = 10.\n",
    "shallow2['nframe'] = 2\n",
    "shallow2['nskip'] = 3\n",
    "\n",
    "bright2 = {}\n",
    "bright2['tgroup'] = 21.2\n",
    "bright2['ngroup'] = 10.\n",
    "bright2['nframe'] = 2\n",
    "bright2['nskip'] = 0\n",
    "\n",
    "bright1 = {}\n",
    "bright1['tgroup'] = 21.2\n",
    "bright1['ngroup'] = 10.\n",
    "bright1['nframe'] = 1\n",
    "bright1['nskip'] = 1\n",
    "\n",
    "rapid = {}\n",
    "rapid['tgroup'] = 10.73676\n",
    "rapid['ngroup'] = 10.\n",
    "rapid['nframe'] = 1\n",
    "rapid['nskip'] = 0\n",
    "\n",
    "readpatts = {}\n",
    "readpatts['deep8'] = deep8\n",
    "readpatts['deep2'] = deep2\n",
    "readpatts['medium8'] = medium8\n",
    "readpatts['medium2'] = medium2\n",
    "readpatts['shallow4'] = shallow4\n",
    "readpatts['shallow2'] = shallow2\n",
    "readpatts['bright2'] = bright2\n",
    "readpatts['bright1'] = bright1\n",
    "readpatts['rapid'] = rapid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NCDHAS pipeline requires data to be in **FITSWriter format**. The test data should already be in this format. \n",
    "\n",
    "** FITSWriter format (science data in the PRIMARY extension)**:\n",
    "\n",
    "        In [6]: from astropy.io import fits\n",
    "        In [7]: fits.info(\"NRCV82600049001P0000000002102.fits\")\n",
    "        Filename: NRCV82600049001P0000000002102.fits\n",
    "        No.    Name         Type      Cards   Dimensions   Format\n",
    "            0  PRIMARY     PrimaryHDU     381   (320, 320, 20) int16 (rescales to uint16)  \n",
    "            1  ENG         BinTableHDU     15   78148R x 3C  [30A, 30A, 30A\n",
    "\n",
    "**SSB format (science data in the SCI extension)**:\n",
    "\n",
    "        In [1]: from astropy.io import fits \n",
    "        In [2]: fits.info(\"NRCNRCA1-DARK-60012216201_uncal.fits\")\n",
    "        Filename: NRCNRCA1-DARK-60012216201_uncal.fits\n",
    "        No.    Name         Type      Cards   Dimensions   Format\n",
    "              0  PRIMARY     PrimaryHDU     392   ()     \n",
    "              1  SCI         ImageHDU        10   (2048, 2048, 108, 1)   float32  \n",
    "              2  PIXELDQ     ImageHDU        10   (2048, 2048) int32 (rescales to uint32)  \n",
    "              3  GROUPDQ     ImageHDU        10   (2048, 2048, 108, 1)   uint8  \n",
    "              4  ERR         ImageHDU        10   (2048, 2048, 108, 1)   float32  \n",
    "              5  ASDF        ImageHDU         7   (1811965775,)   uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and check the raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uncalFile = \"NRCV82600049001P0000000002102_1_490_SE_2016-01-18T12h59m56.fits\"\n",
    "fileBase = uncalFile[:-5]\n",
    "\n",
    "# use astropy to access the data\n",
    "with fits.open(uncalFile) as h:\n",
    "    h.info()\n",
    "    imageUncal = h[0].data\n",
    "    ngroups = np.shape(imageUncal)[0]\n",
    "    mode = 'RAPID'\n",
    "    \n",
    "# display the first group of the image \n",
    "# vmin/vmax match ds9 scale limits or the limits of the data\n",
    "# use sigma_clipped_stats to get mean for image limits\n",
    "mean,med,std = sigma_clipped_stats(imageUncal[0,:,:],sigma=3)\n",
    "display_img(imageUncal[0,:,:],mean-2000,mean+2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram of the values in the first group\n",
    "plt.figure(figsize=(8, 5))\n",
    "bin_vals,bins,patches = plt.hist(np.ravel(imageUncal[0,:,:]),bins=np.arange(0,mean+10000,1000),range=(0,mean+10000),label='data')\n",
    "plt.xlabel('value',fontsize=15)\n",
    "plt.ylabel('$N_{pix}$',fontsize=15)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose pixels to study throughout calibration steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at weird pixels: peak of PSF (saturated), CRs, hot pixels, etc.\n",
    "# ** note that python coords start from 0,0 and there is a 4 pixel wide border of reference pixels around the detector **\n",
    "\n",
    "repx =  105       # random pix x\n",
    "repy = 102        # random pix y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot uncalibrated ramp\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(15,8))\n",
    "ax = plot_pixel(imageUncal, repx, repy,'rep pix',ax, 'blue',0,mean+10000, 0,ngroups+1, mode)\n",
    "f.text(0.5, -0.02, 'Time (sec)', ha='center', fontsize=12)\n",
    "f.text(0.5, 1.04, 'pixel [%s,%s]'% (str(repx),str(repy)), ha='center', fontsize=14)\n",
    "f.text(-0.005, 0.5, 'Signal (DN)', va='center', rotation='vertical', fontsize=12)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check baseline values for data\n",
    "\n",
    "print('\\nFor representative pixel:')\n",
    "print('IMAGE:',imageUncal[:,repy,repx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On to calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes about running NCDHAS pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NCDHAS pipeline automatically runs the full ramps-to-slopes calibration steps, which include:\n",
    "        \n",
    "        data quality initialization\n",
    "        IPC correction\n",
    "        reference correction\n",
    "        detect saturation\n",
    "        dark correction\n",
    "        linearity correction\n",
    "        detect CRs\n",
    "        slope fitting\n",
    "        flat field\n",
    "\n",
    "The outputs of the NCDHAS pipeline are:\n",
    "        \n",
    "        calibrated file (*.red.fits)\n",
    "        slope image (*.slp.fits) \n",
    "        diagnostic file (*.dia.fits)  \n",
    "        \n",
    "It doesn't allow an easy way to run intermediate steps alone, or output intermediate step results. In order to do that, you must turn off the steps you don't want using flags (note, some steps have many extra flags). For a full explanation of steps and commands, read the document (the appendix has all possible flags for all the steps): https://confluence.stsci.edu/download/attachments/94098809/NIRCam-GSW-01_RevB.pdf?version=1&modificationDate=1501274509187&api=v2\n",
    "\n",
    "** Here are some the main flags**:\n",
    "\n",
    "    Data quality\n",
    "        −/+cbp     Controls whether bad pixel masking is done (+ for ON, - for OFF). \n",
    "                    DEFAULT: ON, do bad pixel masking\n",
    "        −/+BPf     User specified bad pixel mask (e.g. +BPf /dir/to/file.fits).\n",
    "        \n",
    "    IPC correction\n",
    "        ‐/+ipc     Controls whether IPC deconvolution is done.  \n",
    "                    DEFAULT: OFF, no IPC deconvolution done\n",
    "        ‐/+IPCf    Use the specified IPC deconvolution kernel file.\n",
    "        \n",
    "    Reference pixel\n",
    "        ‐dr        Controls whether reference correction is done. If set (-dr), no reference correction done.  \n",
    "                    DEFAULT: OFF, reference corrections are always done unless ‘‘-dr'' is specified.  \n",
    "\n",
    "    Saturation\n",
    "        ‐/+cs      Controls whether saturation detection is done on the ramp.\n",
    "                    DEFAULT: ON, saturation detection done\n",
    "        ‐/+WDf     User specified well depth map.\n",
    "\n",
    "    Dark current & bias\n",
    "        ‐/+cd      Controls whether a dark calibration is done.\n",
    "                    DEFAULT: OFF, no dark calibration done\n",
    "        ‐/+cbs     Controls whether a bias correction is accounted for. If set (+cbs, attempt to load a file)   \n",
    "                    DEFAULT: OFF, no bias correction is done from a file \n",
    "        ‐/+be      Controls whether a bias estimator is computed, see GSW-02.\n",
    "                    DEFAULT: OFF \n",
    "        ‐/+Df      User the specified dark frame.  \n",
    "        \n",
    "    Linearity\n",
    "        ‐/+cl      Controls whether linearity calibration is done. If set (+cl), load a calibration file.\n",
    "                    DEFAULT: OFF, no linearity calibration is done from a file\n",
    "        ‐/+Lf      Use the specified linearity calibration file. \n",
    "         \n",
    "    CR detection (TBD)\n",
    "        -/+cr      Controls whether or not a CR detection is done in the old version.         \n",
    "        ‐/+fmp     Maximum number of positive two point differences to auto reject \n",
    "                    DEFAULT: 1          \n",
    "        ‐/+fmn     Maximum number of negative two point differences to auto reject \n",
    "                    DEFAULT: 1 \n",
    "        ‐/+fmi     Maximum number of iterations, two point difference rejection.\n",
    "                    DEFAULT: 0 \n",
    "        ‐/+fls     Lower sigma threshold in interative two point difference rejection.  \n",
    "                    DEFAULT: 3                     \n",
    "        ‐/+fhs     Upper sigma threshold in interative two point difference  rejection. \n",
    "                    DEFAULT: 3 \n",
    "                    \n",
    "    Slope fitting\n",
    "        ‐/+df      Number of initial frames to drop when fitting the ramp.   \n",
    "                    DEFAULT:  Default is set based on configuration for \"AZ\" configurations, \n",
    "                              set to 1, for flight configurations, set to 0. \n",
    "        ‐/+nf      Number of frames to include in fit, excluding drop frames. NIRCam Science Data Pipeline \n",
    "                    Description NIRCam0021=DRD GSW-01Revision B 3-32 Setting '‐df 2 ‐nf 10' will result in \n",
    "                    frames 3-12 being used in fit. Note that setting \"nf\" will override the use of a \n",
    "                    saturation mask. If you set nf, the saturation mask will be turned off. \n",
    "                    DEFAULT: NR-df (eg. all frames except initial drops). \n",
    "        ‐/+or      Order of the polynomial to use in the ramp fit. \n",
    "                    DEFAULT: 1  Actually, here DEFAULT means only allowed value.\n",
    "        ‐/+cr      Do cosmic ray detection. Not implemented! \n",
    "                    DEFAULT: FALSE \n",
    "        ‐/+mf      Minimum number of frames to use in fit.  This will control the minimum number \n",
    "                    of frames needed for a given pixel for ramp fitting to proceed.  Note that this will \n",
    "                    also control the minimum number of frames per segment if CR detection is turned on.                     \n",
    "                    DEFAULT: 3   \n",
    "                    \n",
    "    Flat field\n",
    "        ‐/+cf      Controls whether the flat field is applied.\n",
    "                    DEFAULT: OFF, do not apply flat field         \n",
    "        -/+FFf     Use the specified flat field file file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ramps-to-slopes pipeline: NCDHAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CV3 testing, Karl had a special flag ( **isimcv3** ) to tell the pipeline that he was running it on CV3 test data:\n",
    "\n",
    "        % ncdhas NRCV80818839558.fits +cfg isimcv3\n",
    "        \n",
    "I don't know if this will be the case for the new OTIS test data. Regardless, this is generally how you run his pipeline.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get help with pipeline steps by typing: ncdhas -h (for help file)\n",
    "\n",
    "# the command is simply: $ ncdhas file.fits\n",
    "uncalFile = \"NRCV82600049001P0000000002102_1_490_SE_2016-01-18T12h59m56.fits\"\n",
    "cmd = \"ncdhas \"+uncalFile\n",
    "print(\"Running command:\\n\\n\")\n",
    "print(cmd)\n",
    "print('\\n\\nin the command line.')\n",
    "os.system(cmd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output that prints in the terminal window looks like this:\n",
    "\n",
    "---> Start: Setting up run parameters\n",
    " \n",
    " --- Using config file /grp/software/Linux/RH6/x86_64/ncdhas/NIRCam.cfg\n",
    " \n",
    " --- Book keeping stuff:\n",
    " \n",
    " -- Overwrite set to false\n",
    " \n",
    " -- WriteIntermediate set to true\n",
    " \n",
    " -- WriteSlope set to true\n",
    " \n",
    " -- WriteDiagnostic set to true\n",
    " \n",
    " -- MaxRAM set to 512MB\n",
    " \n",
    " -- Reducing CDS ramp set to false\n",
    " \n",
    " -- Zero Indexing set to true\n",
    " \n",
    " --- Reference Pixel Configuration: \n",
    " \n",
    " -- DoReference set to true\n",
    " \n",
    " -- ExcludeBottom set to false\n",
    " \n",
    " -- SubFirstFrame set to false\n",
    " \n",
    " -- refColCor set to true\n",
    " \n",
    " -- refSigRej set to true\n",
    " \n",
    " -- refnIter set to 3\n",
    " \n",
    " -- refLower set to 3\n",
    " \n",
    " -- refUpper set to 3\n",
    " \n",
    " -- Side reference subtraction set to false\n",
    " \n",
    " -- Side reference high frequency correction set to false\n",
    " \n",
    " --- Calibration stuff: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCDHAS ramps-to-slopes outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I haven't been able to find where detailed information on the outputs lives, but you can poke around in the data files and figure out what they are. For example, the diagnostic file should contain information on bad pixels. The reduced data file holds the calibrated ramps. The slope file contains the slopes and the uncertainties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read and print the results of the NCDHAS pipeline\n",
    "\n",
    "print('\\nDiagnostic:')\n",
    "with fits.open(\"NRCV82600049001P0000000002102_1_490_SE_2016-01-18T12h59m56.dia.fits\") as d:\n",
    "    diagnostic = d[0].data\n",
    "    d.info()\n",
    "    \n",
    "print('\\nReduced:')\n",
    "with fits.open(\"NRCV82600049001P0000000002102_1_490_SE_2016-01-18T12h59m56.red.fits\") as r:\n",
    "    reduced = r[0].data\n",
    "    r.info()\n",
    "    \n",
    "print('\\nSlope:')    \n",
    "with fits.open(\"NRCV82600049001P0000000002102_1_490_SE_2016-01-18T12h59m56.slp.fits\") as s:\n",
    "    slopes = s[0].data[0,:,:]\n",
    "    err = s[0].data[1,:,:]\n",
    "    s.info()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reduced data pixel ramp\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(15,8))\n",
    "ax = plot_pixel(reduced, repx, repy,'rep pix',ax, 'blue',0,mean+10000, 0,ngroups+1, mode)\n",
    "f.text(0.5, -0.02, 'Time (sec)', ha='center', fontsize=12)\n",
    "f.text(0.5, 1.04, 'pixel [%s,%s]'% (str(repx),str(repy)), ha='center', fontsize=14)\n",
    "f.text(-0.005, 0.5, 'Signal (DN)', va='center', rotation='vertical', fontsize=12)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the slope image\n",
    "\n",
    "print('\\nFor representative pixel:')\n",
    "print('IMAGE:',slopes[repy,repx])\n",
    "print('ERR:',err[repy,repx])\n",
    "\n",
    "# display the rates\n",
    "# vmin/vmax match ds9 scale limits or the limits of the data\n",
    "# use sigma_clipped_stats to get mean for rate limits\n",
    "\n",
    "rate_mean,rate_med,rate_std = sigma_clipped_stats(slopes,sigma=3)\n",
    "display_img(slopes,rate_mean-10,rate_mean+50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram of the values in the first group\n",
    "plt.figure(figsize=(8, 5))\n",
    "bin_vals,bins,patches = plt.hist(np.ravel(slopes),bins=np.arange(rate_mean-100,rate_mean+100,20),range=(rate_mean-100,rate_mean+100),label='data')\n",
    "plt.xlabel('rate',fontsize=15)\n",
    "plt.ylabel('$N_{pix}$',fontsize=15)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning on/off certain pipeline steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, it is a little tricky to change the calibration steps performed by the pipeline. You need to turn off all the steps that you don't want to perform. As a weird example, if you want to turn off superbias, refpix, and linearity, the command is:\n",
    "\n",
    "        % ncdhas NRCV82600049001P0000000002102 -dr -ipc -cbs -cl \n",
    "\n",
    "Or to give the pipeline a configuration file (for instance, for CV3 test data) and turn on the flat field step with your own PFlat reference file:\n",
    "\n",
    "        % ncdhas NRCV82600049001P0000000002102 +cfg isimcv3 +cf +FFf /dir/to/file/PFlat.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Input and output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display images from each step\n",
    "\n",
    "columns = 1\n",
    "titles = ['uncalibrated','calibrated']\n",
    "vmins = [mean-1000,-10]\n",
    "vmaxs = [mean+1000,10]\n",
    "images = [imageUncal[0,:,:],slopes]\n",
    "for i, image in enumerate(images):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image,vmin=vmins[i],vmax=vmaxs[i], cmap=plt.cm.gray)\n",
    "    plt.colorbar(orientation='horizontal',pad=0.1) \n",
    "    plt.title(titles[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
