{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSEG data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code that can be used to validate data created during GSEG3. It reads in the APT-derived xml and pointing files and constructs a dictionary of expected data properties. It then compares these properties to the information contained in the headers of the actual data to look for inconsistencies.\n",
    "\n",
    "**Mirage and pysiaf are dependencies. Be sure they are installed in your environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from astropy.io import fits\n",
    "from mirage.yaml import yaml_generator\n",
    "from mirage.apt import apt_inputs\n",
    "from mirage.utils.siaf_interface import sci_subarray_corners\n",
    "from mirage.utils.utils import calc_frame_time\n",
    "from mirage.yaml.generate_observationlist import get_observation_dict\n",
    "import numpy as np\n",
    "import pysiaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords to check\n",
    "UNCAL_KEYWORDS = ['SUBARRAY', 'DETECTOR', 'NINTS', 'NGROUPS', 'NAXIS', 'EFFEXPTM',\n",
    "                  'LONGFILTER', 'LONGPUPIL', 'SHORTFILTER', 'SHORTPUPIL', 'READPATT',\n",
    "                  'OBSLABEL', 'EXP_TYPE', 'TITLE', 'OBSERVTN', 'TEMPLATE',\n",
    "                  'EXPRIPAR', 'SUBSTRT1', 'SUBSTRT2', 'SUBSIZE1', 'SUBSIZE2',\n",
    "                  'FASTAXIS', 'SLOWAXIS', 'PATTTYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corresponding keywords in the APT-derived dictionary\n",
    "# These must correspond one-to-one with UNCAL_KEYWORDS ABOVE\n",
    "UNCAL_TABLE_KEYWORDS = ['Subarray', None, 'Integrations', 'Groups', None, None,\n",
    "                        'LongFilter', 'LongPupil', 'ShortFilter', 'ShortPupil', 'ReadoutPattern',\n",
    "                        'ObservationName', 'Mode', 'Title', 'ObservationID', 'APTTemplate',\n",
    "                        'ParallelInstrument', None, None, None, None,\n",
    "                        None, None, 'PrimaryDitherType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTEGER_KEYWORDS = ['Integrations', 'Groups']\n",
    "FLOAT_KEYWORDS = ['EFFEXPTM']\n",
    "FILTER_KEYWORDS = ['LONGFILTER', 'LONGPUPIL', 'SHORTFILTER', 'SHORTPUPIL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For FASTAXIS and SLOWAXIS\n",
    "HORIZONTAL_FLIP = ['NRCA1', 'NRCA3', 'NRCALONG', 'NRCB2', 'NRCB4']\n",
    "VERTICAL_FLIP = ['NRCA2', 'NRCA4', 'NRCB1', 'NRCB3', 'NRCBLONG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_exptype(value):\n",
    "    \"\"\"Modify the exposure type as listed in the exposure table\n",
    "    to match one of the strings as used in the fits files.\n",
    "    e.g. 'imaging' becomes 'NRC_IMAGE'\n",
    "    Remember that currently, Mirage only knows imaging and wfss\n",
    "    \"\"\"\n",
    "    if value == 'imaging':\n",
    "        return 'NRC_IMAGE'\n",
    "    elif value == 'wfss':\n",
    "        return 'NRC_GRISM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_files(exp_dict, index):\n",
    "    \"\"\"Calculate the total number of files expected for an\n",
    "    observation based on the number of dithers and the module.\n",
    "    ASSUME that all detectors in a given module are used. This\n",
    "    assumption will not be true for some WFSC apertures.\n",
    "    \"\"\"\n",
    "    module = exp_dict['Module'][index]\n",
    "    number_of_dithers = exp_dict['number_of_dithers'][index]\n",
    "    if module in ['A', 'B']:\n",
    "        dets = 5\n",
    "    else:\n",
    "        dets = 10\n",
    "    total = number_of_dithers * dets\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_file_lists(uncal, rate):\n",
    "    \"\"\"Given lists of uncal and rate files corresponding to a single\n",
    "    observation, adjust the lists to be the same length, adding in\n",
    "    None for any files that are missing in a given list\n",
    "    \"\"\"\n",
    "    udict = {}\n",
    "    rdict = {}\n",
    "    expanded_rate = []\n",
    "    expanded_uncal = []\n",
    "\n",
    "    # Loop through uncal files and look for matching rate files\n",
    "    for ufile in uncal:\n",
    "        dirname, filename = os.path.split(ufile)\n",
    "        base = filename.strip('_uncal.fits')\n",
    "        fullbase = os.path.join(dirname, base)\n",
    "        found = False\n",
    "        for rfile in rate:\n",
    "            if fullbase in rfile:\n",
    "                found = True\n",
    "                break\n",
    "        udict[base] = found\n",
    "\n",
    "    # Loop through rate files and look for matching uncal files\n",
    "    for rfile in rate:\n",
    "        dirname, filename = os.path.split(rfile)\n",
    "        base = filename.strip('_rate.fits')\n",
    "        fullbase = os.path.join(dirname, base)\n",
    "        found = False\n",
    "        for ufile in uncal:\n",
    "            if fullbase in ufile:\n",
    "                found = True\n",
    "                break\n",
    "        rdict[base] = found\n",
    "\n",
    "    # Fill in missing files, in either uncal or rate lists,\n",
    "    # with None\n",
    "    for ukey in udict:\n",
    "        expanded_uncal.append(ukey + '_uncal.fits')\n",
    "        if udict[key]:\n",
    "            expanded_rate.append(ukey + '_rate.fits')\n",
    "        else:\n",
    "            expanded_rate.append(None)\n",
    "    for rkey in rdict:\n",
    "        if not rdict[key]:\n",
    "            expanded_rate.append(rkey + '_rate.fits')\n",
    "            expanded_uncal.append(None)\n",
    "    return expanded_uncal, expanded_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fastaxis(detector):\n",
    "    \"\"\"Identify the values of FASTAXIS and SLOWAXIS based on the detector\n",
    "    name\n",
    "    \"\"\"\n",
    "    if detector in HORIZONTAL_FLIP:\n",
    "        fast = -1\n",
    "        slow = 2\n",
    "    elif detector in VERTICAL_FLIP:\n",
    "        fast = 1\n",
    "        slow = -2\n",
    "    return fast, slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    \"\"\"Read in the given fits file and return the data and header\n",
    "    \"\"\"\n",
    "    with fits.open(filename) as h:\n",
    "        signals = h['SCI'].data\n",
    "        header0 = h[0].header\n",
    "        header1 = h[1].header\n",
    "    return signals, header0, header1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncal_header_keywords(head):\n",
    "    \"\"\"Extract values for the desired keywords from the given header\n",
    "    \"\"\"\n",
    "    file_info = {}\n",
    "    for keyword in UNCAL_KEYWORDS:\n",
    "        try:\n",
    "            info = head[keyword]\n",
    "        except KeyError:\n",
    "            if 'FILTER' in keyword:\n",
    "                info = head['FILTER']\n",
    "            elif 'PUPIL' in keyword:\n",
    "                info = head['PUPIL']\n",
    "            else:\n",
    "                info = None\n",
    "\n",
    "        file_info[keyword] = info\n",
    "    return file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncal_table_info(values, index):\n",
    "    \"\"\"Extract information from the exposure table that matches the\n",
    "    header keyword values in uncal_header_keyword\n",
    "    \"\"\"\n",
    "    values_dict = {}\n",
    "    for table_keyword, file_keyword in zip(UNCAL_TABLE_KEYWORDS, UNCAL_KEYWORDS):\n",
    "        if table_keyword is not None:\n",
    "            if table_keyword in INTEGER_KEYWORDS:\n",
    "                value = int(values[table_keyword][index])\n",
    "            else:\n",
    "                value = values[table_keyword][index]\n",
    "            values_dict[file_keyword] = value\n",
    "        else:\n",
    "            values_dict[file_keyword] = None\n",
    "    return values_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(xml_file, output_dir, gseg_uncal_files):\n",
    "    \"\"\"MAIN FUNCTION\"\"\"\n",
    "    pointing_file = xml_file.replace('.xml', '.pointing')\n",
    "    gseg_rate_files = [f.replace('uncal', 'rate') for f in gseg_uncal_files]\n",
    "\n",
    "    catalogs = {'nircam': {'sw': 'nothing.cat', 'lw': 'nothing.cat'}}\n",
    "\n",
    "    observation_list_file = os.path.join(output_dir, 'observation_list.yaml')\n",
    "    apt_xml_dict = get_observation_dict(xml_file, observation_list_file, catalogs,\n",
    "                                    verbose=True)\n",
    "\n",
    "    observation_list = set(apt_xml_dict['ObservationID'])\n",
    "    int_obs = sorted([int(o) for o in observation_list])\n",
    "    str_obs_list = [str(o).zfill(3) for o in int_obs]\n",
    "\n",
    "    for observation_to_check in str_obs_list:\n",
    "        print('')\n",
    "        print('')\n",
    "        print('OBSERVATION: {}'.format(observation_to_check))\n",
    "        print('')\n",
    "\n",
    "        good = np.where(np.array(apt_xml_dict['ObservationID']) == observation_to_check)\n",
    "\n",
    "        try:\n",
    "            total_expected_files = calculate_total_files(apt_xml_dict, good[0][0])\n",
    "            print('Total number of expected files: {}'.format(total_expected_files))\n",
    "        except IndexError:\n",
    "            print(\"No files found.\")\n",
    "            continue\n",
    "\n",
    "        # The complication here is that the table created by Mirage does not have a filename\n",
    "        # attached to each entry. So we need a way to connect an actual filename\n",
    "        # to each entry\n",
    "        subdir_start = 'jw' + apt_xml_dict['ProposalID'][good[0][0]] + observation_to_check.zfill(3)\n",
    "        matching_uncal_files = sorted([filename for filename in gseg_uncal_files if subdir_start in filename])\n",
    "        matching_rate_files = sorted([filename for filename in gseg_rate_files if subdir_start in filename])\n",
    "        print('Found uncal files:')\n",
    "        for i in range(len(matching_uncal_files)):\n",
    "            print(matching_uncal_files[i])\n",
    "        print('')\n",
    "        print('Found rate files:')\n",
    "        for i in range(len(matching_rate_files)):\n",
    "            print(matching_rate_files[i])\n",
    "        print('')\n",
    "\n",
    "        # Check to see if any files are missing\n",
    "        if len(matching_uncal_files) != total_expected_files:\n",
    "            print(\"WARNING: Missing uncal files for observation {}. Expected {} files, found {}.\".format(observation_to_check, total_expected_files, len(matching_uncal_files)))\n",
    "        if len(matching_rate_files) != total_expected_files:\n",
    "            print(\"WARNING: Missing rate files for observation {}. Expected {} files, found {}.\".format(observation_to_check, total_expected_files, len(matching_rate_files)))\n",
    "\n",
    "        # Deal with the case of matching_uncal_files and matching_rate_files having\n",
    "        # different lengths here. In order to loop over them they must have the same length\n",
    "        if len(matching_uncal_files) != len(matching_rate_files):\n",
    "            (matching_uncal_files, matching_rate_files) = equalize_file_lists(matching_uncal_files, matching_rate_files)\n",
    "            print('Equalized file lists (should have a 1:1 correspondence):')\n",
    "            for idx in range(len(matching_uncal_files)):\n",
    "                print(matching_uncal_files[idx], matching_rate_files[idx])\n",
    "\n",
    "        # Create siaf instance for later calculations\n",
    "        siaf = pysiaf.Siaf('NIRCam')\n",
    "\n",
    "        for uncal, rate in zip(matching_uncal_files, matching_rate_files):\n",
    "            good_uncal = uncal != None\n",
    "            good_rate = rate != None\n",
    "\n",
    "            if good_uncal:\n",
    "                print(\"Checking {}\".format(os.path.split(uncal)[1]))\n",
    "                print('-----------------------------------------------')\n",
    "            elif good_rate:\n",
    "                print(\"Checking {}\".format(os.path.split(rate)[1]))\n",
    "                print('-----------------------------------------------')\n",
    "\n",
    "\n",
    "            if good_uncal:\n",
    "                data, header, sci_header = get_data(uncal)\n",
    "                detector_from_filename = uncal.split('_')[-2].upper()\n",
    "                header_detector = header['DETECTOR']\n",
    "                if 'LONG' in header_detector:\n",
    "                    header_detector = header_detector.replace('LONG', '5')\n",
    "                if header_detector not in header['APERNAME']:\n",
    "                    print((\"WARNING: Detector name and aperture name in file header appear to be incompatible: {}, {}\"\n",
    "                          .format(header['DETECTOR'], header['APERNAME'])))\n",
    "                    print(\"Detector listed in filename: {}\".format(detector_from_filename))\n",
    "                    print('If the aperture is incorrect then the calculated subarray location from pysiaf will also be incorrect.')\n",
    "                data_shape = data.shape\n",
    "\n",
    "                # Get info from header to be compared\n",
    "                header_vals = uncal_header_keywords(header)\n",
    "\n",
    "                # Get matching data from the exposure table\n",
    "                table_vals = uncal_table_info(apt_xml_dict, good[0][0])\n",
    "\n",
    "                # Make some adjustments to the exposure table info\n",
    "\n",
    "                # Calucate the exposure time\n",
    "                aperture = header['APERNAME']  # could also try APERNAME, PPS_APER\n",
    "\n",
    "                print('Aperture listed in header is: {}'.format(aperture))\n",
    "\n",
    "                num_amps = 1\n",
    "                frametime = calc_frame_time('NIRCam', aperture, data_shape[-1], data_shape[-2], num_amps)\n",
    "                table_vals['EFFEXPTM'] = frametime * int(table_vals['NGROUPS'])\n",
    "\n",
    "                # NAXIS\n",
    "                table_vals['NAXIS'] = len(data.shape)\n",
    "                header_vals['NAXIS'] = sci_header['NAXIS']\n",
    "\n",
    "                # Use pysiaf to calculate subarray locations\n",
    "                try:\n",
    "                    xc, yc = sci_subarray_corners('NIRCam', aperture, siaf=siaf)\n",
    "                    table_vals['SUBSTRT1'] = xc[0] + 1\n",
    "                    table_vals['SUBSTRT2'] = yc[0] + 1\n",
    "                    table_vals['SUBSIZE1'] = siaf[aperture].XSciSize\n",
    "                    table_vals['SUBSIZE2'] = siaf[aperture].YSciSize\n",
    "                except KeyError:\n",
    "                    print(\"ERROR: Aperture {} is not a valid aperture in pysiaf\".format(aperture))\n",
    "                    xc = [-2, -2]\n",
    "                    yc = [-2, -2]\n",
    "                    table_vals['SUBSTRT1'] = xc[0] + 1\n",
    "                    table_vals['SUBSTRT2'] = yc[0] + 1\n",
    "                    table_vals['SUBSIZE1'] = 9999\n",
    "                    table_vals['SUBSIZE2'] = 9999\n",
    "\n",
    "                # Create FASTAXIS and SLOWAXIS values based on the detector name\n",
    "                fast, slow = find_fastaxis(header_vals['DETECTOR'])\n",
    "                table_vals['FASTAXIS'] = fast\n",
    "                table_vals['SLOWAXIS'] = slow\n",
    "\n",
    "                # Remove whitespace from observing template in file\n",
    "                header_vals['TEMPLATE'] = header_vals['TEMPLATE'].replace(' ', '').lower()\n",
    "                table_vals['TEMPLATE'] = table_vals['TEMPLATE'].lower()\n",
    "\n",
    "                # Adjust prime/parallel boolean from table to be a string\n",
    "                if not table_vals['EXPRIPAR']:\n",
    "                    table_vals['EXPRIPAR'] = 'PRIME'\n",
    "                else:\n",
    "                    table_vals['EXPRIPAR'] = 'PARALLEL'\n",
    "\n",
    "                # Change exposure type from table to match up with\n",
    "                # types of strings in the file\n",
    "                table_vals['EXP_TYPE'] = adjust_exptype(table_vals['EXP_TYPE'])\n",
    "\n",
    "                # Set the DETECTOR field to be identical. This info is not in the\n",
    "                # exposure table, so we can't actually check it\n",
    "                table_vals['DETECTOR'] = header_vals['DETECTOR']\n",
    "\n",
    "                # Compare the actual data shape to the shape given in the header\n",
    "                header_shape = (header_vals['NINTS'], header_vals['NGROUPS'], header_vals['SUBSIZE2'], header_vals['SUBSIZE1'])\n",
    "                if header_shape != data_shape:\n",
    "                    print(\"WARNING: Shape of data in the file does not match that specified in the header.\")\n",
    "                    print('Data shape: {}'.format(data_shape))\n",
    "                    print('Header shape: {}'.format(header_shape))\n",
    "\n",
    "                # Now compare the data in the dictionary from the file versus that\n",
    "                # from the exposure table created from the APT file\n",
    "                err = False\n",
    "                for key in header_vals:\n",
    "                    if header_vals[key] != table_vals[key]:\n",
    "                        if key not in FLOAT_KEYWORDS and key not in FILTER_KEYWORDS:\n",
    "                            err = True\n",
    "                            print('MISMATCH: {}, in exp table: {}, in file: {}'.format(key, table_vals[key], header_vals[key]))\n",
    "                        elif key in FLOAT_KEYWORDS:\n",
    "                            if not np.isclose(header_vals[key], table_vals[key], rtol=0.01, atol=0.):\n",
    "                                err = True\n",
    "                                print('MISMATCH: {}, in exp table: {}, in file: {}'.format(key, table_vals[key], header_vals[key]))\n",
    "\n",
    "                        if key in ['LONGFILTER', 'LONGPUPIL'] and 'LONG' in header_vals['DETECTOR']:\n",
    "                            err = True\n",
    "                            print('MISMATCH: {}, in exp table: {}, in file: {}'.format(key, table_vals[key], header_vals[key]))\n",
    "                        if key in ['SHORTFILTER', 'SHORTPUPIL'] and 'LONG' not in header_vals['DETECTOR']:\n",
    "                            err = True\n",
    "                            print('MISMATCH: {}, in exp table: {}, in file: {}'.format(key, table_vals[key], header_vals[key]))\n",
    "\n",
    "                if not err:\n",
    "                    print('No inconsistencies. File header info correct.')\n",
    "\n",
    "            print('')\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = '/path/to/proposal/xml/file/00617.xml'\n",
    "output_dir = '/location/to/place/outputs/'\n",
    "gseg_uncal_files = glob('/path/to/gseg/files/*uncal.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate(xml_file, output_dir, gseg_uncal_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
